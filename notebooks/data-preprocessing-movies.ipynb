{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Cleaning the Movies dataset by using external sources\n",
    "---\n",
    "A problem faced when working on the combination of the Movies and IMDB datasets was the different encoding of language \n",
    "and country in the respective attributes. In the IMDB dataset, countries and languages are written in their complete \n",
    "form, while the ISO codes are used in the Movielens dataset. \n",
    "\n",
    "To improve the performance of the matching algorithm it is possible to perform a preprocessing step that employs \n",
    "external ground truth to have a common dictionary between the two datasets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the required starting datasets\n",
    "df1 = pd.read_csv('../pipeline/experiments/imdb_numeric.csv')\n",
    "df2 = pd.read_csv('../pipeline/experiments/movies_reduced.csv')\n",
    "df1 = df1.fillna('')\n",
    "df2 = df2.fillna('')\n",
    "# Removing capitalization and spaces\n",
    "for col in df1.columns:\n",
    "    if df1[col].dtype == 'object':\n",
    "        df1[col] = df1[col].str.replace(' ', '_').str.strip().str.lower()\n",
    "        df1[col] = df1[col].replace('ukn', '')\n",
    "        df1[col] = df1[col].replace(np.nan, '')\n",
    "\n",
    "for col in df2.columns:\n",
    "    if df2[col].dtype == 'object':\n",
    "        df2[col] = df2[col].str.replace(' ', '_').str.strip().str.lower()\n",
    "        df2[col] = df2[col].replace('ukn', '')\n",
    "        df2[col] = df2[col].replace(np.nan, '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replacing  countries with country codes\n",
    "The mapping between country codes and country names was taken from open online sources and cleaned up to remove \n",
    "capitalization and spaces (this was a necessary step because of how the ER algorithm works). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afghanistan : af\n",
      "akrotiri : ax\n",
      "albania : al\n",
      "algeria : ag\n",
      "american_samoa : aq\n",
      "andorra : an\n",
      "angola : ao\n",
      "anguilla : av\n",
      "antarctica : ay\n",
      "antigua_and_barbuda : ac\n",
      "argentina : ar\n",
      "armenia : am\n",
      "aruba : aa\n",
      "ashmore_and_cartier_islands : at\n",
      "australia : as\n",
      "austria : au\n",
      "azerbaijan : aj\n",
      "\"bahamas : _the\"\n",
      "bahrain : ba\n",
      "baker_island : fq\n",
      "bangladesh : bg\n",
      "barbados : bb\n",
      "bassas_da_india : bs\n",
      "belarus : bo\n",
      "belgium : be\n",
      "belize : bh\n",
      "benin : bn\n",
      "bermuda : bd\n",
      "bhutan : bt\n",
      "bolivia : bl\n",
      "bosnia_and_herzegovina : bk\n",
      "botswana : bc\n",
      "bouvet_island : bv\n",
      "brazil : br\n",
      "british_indian_ocean_territory : io\n",
      "british_virgin_islands : vi\n",
      "brunei : bx\n",
      "bulgaria : bu\n",
      "burkina_faso : uv\n",
      "burma : bm\n",
      "burundi : by\n",
      "cabo_verde : cv\n",
      "cambodia : cb\n",
      "cameroon : cm\n",
      "canada : ca\n",
      "cayman_islands : cj\n",
      "central_african_republic : ct\n",
      "chad : cd\n",
      "chile : ci\n",
      "china : ch\n",
      "christmas_island : kt\n",
      "clipperton_island : ip\n",
      "cocos_(keeling)_islands : ck\n",
      "colombia : co\n",
      "comoros : cn\n",
      "\"congo : _republic_of_the\"\n",
      "cook_islands : cw\n",
      "coral_sea_islands : cr\n",
      "costa_rica : cs\n",
      "cote_d'ivoire : iv\n",
      "croatia : hr\n",
      "cuba : cu\n",
      "curacao : uc\n",
      "cyprus : cy\n",
      "czech_republic : ez\n",
      "denmark : da\n",
      "dhekelia : dx\n",
      "djibouti : dj\n",
      "dominica : do\n",
      "dominican_republic : dr\n",
      "ecuador : ec\n",
      "egypt : eg\n",
      "el_salvador : es\n",
      "equatorial_guinea : ek\n",
      "eritrea : er\n",
      "estonia : en\n",
      "eswatini : wz\n",
      "ethiopia : et\n",
      "europa_island : eu\n",
      "falkland_islands_(islas_malvinas) : fk\n",
      "faroe_islands : fo\n",
      "fiji : fj\n",
      "finland : fi\n",
      "france : fr\n",
      "french_guiana : fg\n",
      "french_polynesia : fp\n",
      "french_southern_and_antarctic_lands : fs\n",
      "gabon : gb\n",
      "\"gambia : _the\"\n",
      "gaza_strip : gz\n",
      "georgia : gg\n",
      "germany : gm\n",
      "ghana : gh\n",
      "gibraltar : gi\n",
      "glorioso_islands : go\n",
      "greece : gr\n",
      "greenland : gl\n",
      "grenada : gj\n",
      "guadeloupe : gp\n",
      "guam : gq\n",
      "guatemala : gt\n",
      "guernsey : gk\n",
      "guinea : gv\n",
      "guinea-bissau : pu\n",
      "guyana : gy\n",
      "haiti : ha\n",
      "heard_island_and_mcdonald_islands : hm\n",
      "holy_see_(vatican_city) : vt\n",
      "honduras : ho\n",
      "hong_kong : hk\n",
      "howland_island : hq\n",
      "hungary : hu\n",
      "iceland : ic\n",
      "india : in\n",
      "indonesia : id\n",
      "iran : ir\n",
      "iraq : iz\n",
      "ireland : ei\n",
      "isle_of_man : im\n",
      "israel : is\n",
      "italy : it\n",
      "jamaica : jm\n",
      "jan_mayen : jn\n",
      "japan : ja\n",
      "jarvis_island : dq\n",
      "jersey : je\n",
      "johnston_atoll : jq\n",
      "jordan : jo\n",
      "juan_de_nova_island : ju\n",
      "kazakhstan : kz\n",
      "kenya : ke\n",
      "kingman_reef : kq\n",
      "kiribati : kr\n",
      "\"korea : _south\"\n",
      "kosovo : kv\n",
      "kuwait : ku\n",
      "kyrgyzstan : kg\n",
      "laos : la\n",
      "latvia : lg\n",
      "lebanon : le\n",
      "lesotho : lt\n",
      "liberia : li\n",
      "libya : ly\n",
      "liechtenstein : ls\n",
      "lithuania : lh\n",
      "luxembourg : lu\n",
      "macau : mc\n",
      "madagascar : ma\n",
      "malawi : mi\n",
      "malaysia : my\n",
      "maldives : mv\n",
      "mali : ml\n",
      "malta : mt\n",
      "marshall_islands : rm\n",
      "martinique : mb\n",
      "mauritania : mr\n",
      "mauritius : mp\n",
      "mayotte : mf\n",
      "mexico : mx\n",
      "\"micronesia : _federated_states_of\"\n",
      "midway_islands : mq\n",
      "moldova : md\n",
      "monaco : mn\n",
      "mongolia : mg\n",
      "montenegro : mj\n",
      "montserrat : mh\n",
      "morocco : mo\n",
      "mozambique : mz\n",
      "namibia : wa\n",
      "nauru : nr\n",
      "navassa_island : bq\n",
      "nepal : np\n",
      "netherlands : nl\n",
      "netherlands_antilles : nt\n",
      "new_caledonia : nc\n",
      "new_zealand : nz\n",
      "nicaragua : nu\n",
      "niger : ng\n",
      "nigeria : ni\n",
      "niue : ne\n",
      "norfolk_island : nf\n",
      "north_macedonia : mk\n",
      "northern_mariana_islands : cq\n",
      "norway : no\n",
      "oman : mu\n",
      "pakistan : pk\n",
      "palau : ps\n",
      "palmyra_atoll : lq\n",
      "panama : pm\n",
      "papua_new_guinea : pp\n",
      "paracel_islands : pf\n",
      "paraguay : pa\n",
      "peru : pe\n",
      "philippines : rp\n",
      "pitcairn_islands : pc\n",
      "poland : pl\n",
      "portugal : po\n",
      "puerto_rico : rq\n",
      "qatar : qa\n",
      "reunion : re\n",
      "romania : ro\n",
      "russia : rs\n",
      "rwanda : rw\n",
      "saint_barthelemy : tb\n",
      "\"saint_helena : _ascension\n",
      "saint_kitts_and_nevis : sc\n",
      "saint_lucia : st\n",
      "saint_martin : rn\n",
      "saint_pierre_and_miquelon : sb\n",
      "saint_vincent_and_the_grenadines : vc\n",
      "samoa : ws\n",
      "san_marino : sm\n",
      "sao_tome_and_principe : tp\n",
      "saudi_arabia : sa\n",
      "senegal : sg\n",
      "serbia : ri\n",
      "seychelles : se\n",
      "sierra_leone : sl\n",
      "singapore : sn\n",
      "sint_maarten : nn\n",
      "slovakia : lo\n",
      "slovenia : si\n",
      "solomon_islands : bp\n",
      "somalia : so\n",
      "south_africa : sf\n",
      "south_georgia_and_the_islands : sx\n",
      "south_sudan : od\n",
      "spain : sp\n",
      "spratly_islands : pg\n",
      "sri_lanka : ce\n",
      "sudan : su\n",
      "suriname : ns\n",
      "svalbard : sv\n",
      "sweden : sw\n",
      "switzerland : sz\n",
      "syria : sy\n",
      "taiwan : tw\n",
      "tajikistan : ti\n",
      "tanzania : tz\n",
      "thailand : th\n",
      "timor-leste : tt\n",
      "togo : to\n",
      "tokelau : tl\n",
      "tonga : tn\n",
      "trinidad_and_tobago : td\n",
      "tromelin_island : te\n",
      "tunisia : ts\n",
      "turkey : tu\n",
      "turkmenistan : tx\n",
      "turks_and_caicos_islands : tk\n",
      "tuvalu : tv\n",
      "uganda : ug\n",
      "ukraine : up\n",
      "united_arab_emirates : ae\n",
      "united_kingdom : uk\n",
      "united_states : us\n",
      "uruguay : uy\n",
      "uzbekistan : uz\n",
      "vanuatu : nh\n",
      "venezuela : ve\n",
      "vietnam : vm\n",
      "virgin_islands : vq\n",
      "wake_island : wq\n",
      "wallis_and_futuna : wf\n",
      "west_bank : we\n",
      "western_sahara : wi\n",
      "yemen : ym\n",
      "zambia : za\n",
      "zimbabwe : zi\n"
     ]
    }
   ],
   "source": [
    "# mapping = {}\n",
    "with open('../pipeline/experiments/country_codes.txt', 'r') as fp:\n",
    "    lines = [_.strip().split(',') for idx, _ in enumerate(fp) if idx > 0]\n",
    "    mapping = {line[0]:line[1] for line in lines}\n",
    "\n",
    "for country in mapping:\n",
    "    print('{} : {}'.format(country, mapping[country]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bahamas',\n",
       " 'new_line',\n",
       " 'official_site',\n",
       " 'south_korea',\n",
       " 'soviet_union',\n",
       " 'usa',\n",
       " 'west_germany']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First replacement to clean most of the values.\n",
    "val = df1[['country']].replace(np.nan, '').replace(list(mapping.keys()), list(mapping.values()))\n",
    "# Some countries were not replaced correctly, so I am looking for them among the unique values.\n",
    "[_ for _ in np.unique(val) if len(_) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Missing values are manually replaced\n",
    "df1.loc[df1['country'] == 'official_site', 'country'] = 'united_states'\n",
    "df1.loc[df1['country'] == 'usa', 'country'] = 'united_states'\n",
    "df1.loc[df1['country'] == 'west_germany', 'country'] = 'germany'\n",
    "df1.loc[df1['country'] == 'new_line', 'country'] = ''\n",
    "df1.loc[df1['country'] == 'bahamas', 'country'] = 'bf'\n",
    "df1.loc[df1['country'] == 'south_korea', 'country'] = 'ks'\n",
    "df1.loc[df1['country'] == 'soviet_union', 'country'] = 'rs'\n",
    "df1.loc[df1['country'] == 'usa', 'country'] = 'us'\n",
    "\n",
    "df1[['country']] = df1[['country']].replace(np.nan, '').replace(list(mapping.keys()), list(mapping.values()))\n",
    "df2[['production_countries']] = df2[['production_countries']].replace(np.nan, '').replace(list(mapping.keys()), list(mapping.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Checking if all values have been replaced\n",
    "print([_ for _ in np.unique(df1[['country']]) if len(_) > 2])\n",
    "print([_ for _ in np.unique(df2[['production_countries']]) if len(_) > 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replacing languages with language codes\n",
    "Like in the case described above, language codes have been taken from online open sources. The same sequence of \n",
    "operations is performed again for the language attribute in both datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('../pipeline/experiments/language_codes.txt', 'r') as fp:\n",
    "    lines = [_.strip().split(',') for _ in fp.readlines()]\n",
    "    mapping = {line[0]:line[1] for line in lines}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aboriginal', 'aramaic', 'dari', 'filipino', 'mandarin', 'maya', 'none']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "df1['language'] = df1[['language']].replace(np.nan, '').replace(list(mapping.values()), list(mapping.keys()))\n",
    "\n",
    "print([_ for _ in np.unique(df1[['language']]) if len(_) > 2])\n",
    "print([_ for _ in pd.unique(df2['original_language']) if len(_) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['original_language'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.loc[df1['language'] == 'aboriginal', 'language'] = 'english'\n",
    "df1.loc[df1['language'] == 'aramaic', 'language'] = 'english'\n",
    "df1.loc[df1['language'] == 'filipino', 'language'] = 'english'\n",
    "df1.loc[df1['language'] == 'maya', 'language'] = 'english'\n",
    "df1.loc[df1['language'] == 'none', 'language'] = 'english'\n",
    "df1.loc[df1['language'] == 'dari', 'language'] = 'english'\n",
    "df1.loc[df1['language'] == 'osama', 'language'] = 'pushto'\n",
    "df1.loc[df1['language'] == 'mandarin', 'language'] = 'chinese'\n",
    "df1[['language']] = df1[['language']].replace(np.nan, '').replace(list(mapping.values()), list(mapping.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generating the concatenated dataset\n",
    "The new, combined dataset is built by concatenating the two datasets. To do so, column names are uniformed to align them\n",
    "when concatenating to prepare the dataset used in the ER task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2[['original_language']] = df2[['original_language']].replace(np.nan, '').replace(list(mapping.values()), list(mapping.keys()))\n",
    "df1.rename(columns={\n",
    "    'movie_title': 'title', \n",
    "    'director_name': 'director', \n",
    "    'actor_1_name':'actor_1', \n",
    "    'actor_3_name':'actor_3', \n",
    "    'actor_2_name':'actor_2', \n",
    "    'language': 'original_language', \n",
    "    'country':'production_countries', \n",
    "    'title_year': 'year', \n",
    "    'imdb_score':'vote_average'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spoutnik23/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "concat = pd.concat([df1, df2])\n",
    "concat.rename(columns={\n",
    "    'original_language': 'language',\n",
    "    'production_countries': 'country'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "concat.to_csv('../pipeline/experiments/movies-complete-preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To prepare the dataset used in the Schema Matching task, columns are renamed to avoid having any overlap in the \n",
    "concatenation phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.columns = ['imdb_' + str(_) for _ in range(len(df1.columns))]\n",
    "df2.columns = ['movielens_' + str(_) for _ in range(len(df2.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "concat = pd.concat([df1, df2], ignore_index=True)\n",
    "concat.to_csv('../pipeline/experiments/movies-complete-preprocessed-schema-matching.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (EmbDI)",
   "language": "python",
   "name": "pycharm-f75c726a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
