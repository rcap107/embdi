{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Construction of the Movielens dataset starting from the Movielens completed database\n",
    "---\n",
    "Data in the Movielens database are are spread in different files that were combined in a single csv file to be used in \n",
    "ER and SM tasks. To do so, multiple preprocessing and cleaning steps were required and are reported in this notebook. \n",
    "\n",
    "There are two datasets of interest that will be worked on and merged, `movies_metadata.csv`, which contains metainformation \n",
    "about each movie, such as year of release, country, production company, language; and `credits.csv`, which contains the \n",
    "cast of each movie, as well as information about the crew. \n",
    "\n",
    "The two combined datasets contain a large amount of information that is not present in the `imdb` dataset that should be\n",
    "compared to this database, for this reason it was necessary to drop most of the columns when preparing the experimental \n",
    "version. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preparing the metadata file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the metadata file\n",
    "df = pd.read_csv('../pipeline/experiments/movies_metadata.csv', engine='python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column adult                         : 0 missing values, 0.00% of the total\n",
      "Column belongs_to_collection         : 40972 missing values, 90.12% of the total\n",
      "Column budget                        : 0 missing values, 0.00% of the total\n",
      "Column genres                        : 0 missing values, 0.00% of the total\n",
      "Column homepage                      : 37684 missing values, 82.88% of the total\n",
      "Column id                            : 0 missing values, 0.00% of the total\n",
      "Column imdb_id                       : 17 missing values, 0.04% of the total\n",
      "Column original_language             : 11 missing values, 0.02% of the total\n",
      "Column original_title                : 0 missing values, 0.00% of the total\n",
      "Column overview                      : 954 missing values, 2.10% of the total\n",
      "Column popularity                    : 5 missing values, 0.01% of the total\n",
      "Column poster_path                   : 386 missing values, 0.85% of the total\n",
      "Column production_companies          : 3 missing values, 0.01% of the total\n",
      "Column production_countries          : 3 missing values, 0.01% of the total\n",
      "Column release_date                  : 87 missing values, 0.19% of the total\n",
      "Column revenue                       : 6 missing values, 0.01% of the total\n",
      "Column runtime                       : 263 missing values, 0.58% of the total\n",
      "Column spoken_languages              : 6 missing values, 0.01% of the total\n",
      "Column status                        : 87 missing values, 0.19% of the total\n",
      "Column tagline                       : 25054 missing values, 55.10% of the total\n",
      "Column title                         : 6 missing values, 0.01% of the total\n",
      "Column video                         : 6 missing values, 0.01% of the total\n",
      "Column vote_average                  : 6 missing values, 0.01% of the total\n",
      "Column vote_count                    : 6 missing values, 0.01% of the total\n"
     ]
    }
   ],
   "source": [
    "# Observing the fraction of NAN present in each column\n",
    "n_lines = len(df)\n",
    "for col in df.columns:\n",
    "    countna = df[col].isnull().sum()\n",
    "    countfull = df[col].count()\n",
    "    frac = countna/n_lines*100\n",
    "    print('Column {:30}: {} missing values, {:.2f}% of the total'.format(col, countna, frac))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping the first columns (note that some of these columns contain a large fraction of null values). \n",
    "\n",
    "df = df.drop(['belongs_to_collection', \n",
    "              'homepage', \n",
    "              'imdb_id', \n",
    "              'overview', \n",
    "              'spoken_languages', \n",
    "              'tagline',\n",
    "              'poster_path',\n",
    "              'popularity',\n",
    "             ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# All lines containing an empty title value are dropped.\n",
    "df = df.dropna(subset=['title'])\n",
    "\n",
    "# The id column is redefined as an integer. \n",
    "df.id = df.id.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Additional custom functions were defined to handle missing values and badly formatted entries. Any errors are handled by \n",
    "setting the value to \"UKN\". This value can then be replaced as needed depending on the null value strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# When cleaning genres, only the first value is chosen (multiple genres are possible). If no genre is specified, then \n",
    "# 'Unknown' is given. \n",
    "def clean_genres(ll):\n",
    "    g = ast.literal_eval(ll)\n",
    "    try:\n",
    "        l1 = g[0]['name']\n",
    "        return l1\n",
    "    except IndexError:\n",
    "        return 'Unknown'\n",
    "\n",
    "# The same approach is given to production companies and countries: only the first value in each list is chosen, missing\n",
    "# values are set to unknown. \n",
    "def clean_production_companies(ll):\n",
    "    try:\n",
    "        g = ast.literal_eval(ll)\n",
    "    except ValueError:\n",
    "        return 'UKN'\n",
    "    except SyntaxError:\n",
    "        print(ll)\n",
    "    try:\n",
    "        l1 = g[0]['name']\n",
    "        return l1\n",
    "    except IndexError:\n",
    "        return 'UKN'\n",
    "    except TypeError:\n",
    "        return 'UKN'\n",
    "\n",
    "def clean_production_country(ll):\n",
    "    try:\n",
    "        g = ast.literal_eval(ll)\n",
    "    except ValueError:\n",
    "        return 'UKN'\n",
    "    try:\n",
    "        l1 = g[0]['iso_3166_1']\n",
    "        return l1\n",
    "    except IndexError:\n",
    "        return 'UKN'\n",
    "    except TypeError:\n",
    "        return 'UKN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# After defining the cleaning functions, they are applied to the proper columns. \n",
    "df.genres = df.genres.apply(clean_genres)\n",
    "df.production_companies = df.production_companies.apply(clean_production_companies)\n",
    "df.production_countries = df.production_countries.apply(clean_production_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the crew dataset\n",
    "To reflect the structure of the imdb dataset, we are interested in extracting only a limited subset of the cast, namely\n",
    "the director and the first three billed actors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# clean_cast extracts the first 3 actor names contained by the column main actors.\n",
    "def clean_cast(ll):\n",
    "    g = ast.literal_eval(ll)\n",
    "    main_actors = g[:3]\n",
    "    cleaned_list = [_['name'] for _ in main_actors]\n",
    "    return cleaned_list\n",
    "\n",
    "# clean_crew extracts only the director from the crew. If the director is missing, it is set as Unknown.\n",
    "def clean_crew(ll):\n",
    "    g = ast.literal_eval(ll)\n",
    "    for _ in g:\n",
    "        if _['job'] == 'Director':\n",
    "            return _['name']\n",
    "    return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_cast = pd.read_csv('../pipeline/experiments/credits.csv')\n",
    "\n",
    "# Actors and directors are extracted and the columns are appended to the complete cast dataset. \n",
    "cast = df_cast.cast.apply(clean_cast)\n",
    "c = pd.DataFrame(cast.tolist(), columns=['actor_1', 'actor_2', 'actor_3'])\n",
    "df_cast = pd.concat([df_cast, c], axis=1)\n",
    "df_cast.crew = df_cast.crew.apply(clean_crew)\n",
    "# The crew attribute is replaced by the simpler director attribute\n",
    "df_cast['director'] = df_cast['crew']\n",
    "df_cast.drop('cast', inplace=True, axis=1)\n",
    "\n",
    "df_cast = df_cast.reindex(['id', 'actor_1', 'actor_2', 'actor_3', 'director'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging metadata and cast\n",
    "To obtain the complete dataset, it is then necessary to merge metadata and cast datasets. Some additional cleaning steps are performed here. It is possible to merge the two datasets thanks to the presence of an \"id\" column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge metadata and cast \n",
    "df_movies = pd.merge(df, df_cast, on='id')\n",
    "\n",
    "df_movies.release_date = df_movies.release_date.astype('datetime64')\n",
    "df_movies.budget = df_movies.budget.astype('float64')\n",
    "\n",
    "# This is the complete dataset, which includes many attributes we are not interested in.\n",
    "df_movies.to_csv('movielens.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most unimportant attributes are dropped\n",
    "df_reduced = df_movies.drop(['adult', 'budget', 'id', 'original_title', 'video', 'vote_count', 'revenue', 'runtime'], axis=1)\n",
    "df_reduced['release_date_rounded'] = df_reduced.release_date.dt.strftime('%Y-%m')\n",
    "df_reduced.vote_average = df_reduced.vote_average.round()\n",
    "\n",
    "df_reduced.to_csv('movieslens-reduced.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (EmbDI)",
   "language": "python",
   "name": "pycharm-f75c726a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
